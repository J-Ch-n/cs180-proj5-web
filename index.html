<!-- Referenced https://www.youtube.com/watch?v=i7uJAOFEd4g -->
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <title>CS180 Proj 5</title>
        <link rel="stylesheet" href="https://cdn.lineicons.com/4.0/lineicons.css" />
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
        <link rel="stylesheet" href="style.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>

    <body>
        <div class="wrapper">
            <div id="sidebar"> 
                <div class="sidebar-logo">
                    <a href="#title">Navigation</a>
                </div>
                <ul class="sidebar-nav">
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part0">
                                <span>Part A.0</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part1">
                                <span>Part A.1.1</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part2">
                                <span>Part A.1.2</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part3">
                                <span>Part A.1.3</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part4">
                                <span>Part A.1.4</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part5">
                                <span>Part A.1.5</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part6">
                                <span>Part A.1.6</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part7">
                                <span>Part A.1.7</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part8">
                                <span>Part A.1.8</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#part9">
                                <span>Part A.1.9</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.1.1">
                                <span>Part B.1.1</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.1.2">
                                <span>Part B.1.2</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.2.1">
                                <span>Part B.2.1</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.2.1">
                                <span>Part B.2.2</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.2.1">
                                <span>Part B.2.3</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.2.4">
                                <span>Part B.2.4</span>
                            </a>
                        </button>
                    </li>
                    <li class="sidebar-nav-item">
                        <button type="button" class="btn btn-light">
                            <a href="#partB.2.4">
                                <span>Part B.2.5</span>
                            </a>
                        </button>
                    </li>
                </ul>
            </div>
            <!-- End of sidebar -->
             
            <div class="main">
                <h1 id="title"> CS180 Project 5 </h1>
                <h2 id="part0"> Part A.0: Setup </h2>

                <div class="text-container"> 
                    <h3>An oil painting of a snowy mountain village</h3>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_0_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_0_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_0_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_0_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_0_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_0_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        The prompt for this image was "an oil painting of a snowy mountain village." All of them are relavent to the prompt. However, the more inference steps it 
                        had, the more detailed and less impressionistic the image was. For example, the 4-step inference yielded a very sureal impression of a village, while the 20-step
                        inference yielded a more defined and vibrant version of the same idea. The 10-step inference was somewhere in between. Stage 2 upsampled the outputs of stage 1 images 
                        to get much clearer images.
                    </p>

                    <h3>A man wearing a hat</h3>
                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_1_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_1_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_1_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_1_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_1_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_1_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        The prompt for this image was "a man wearing a hat." All of them seem to be relavent to the prompt. However, the more inference steps it 
                        had, the more detailed and realistic the image was. For example, the 4-step inference yielded an altervative depiction of the prompt, while the 20-step
                        inference yielded a very detailed and almost photographic version of the same idea. The 10-step inference was somewhere in between. Stage 2 upsampled the outputs of stage 1 images 
                        to get much clearer images.
                    </p>

                    <h3>A rocket ship</h3>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_2_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_2_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage1_2_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20 
                                    <br/>
                                    Stage 1
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_2_image_inf_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 4 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_2_image_inf_10.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 10 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 0/stage2_2_image_inf_20.jpg", width="200">
                                <figcaption class="caption"> 
                                    Inference steps: 20 
                                    <br/>
                                    Stage 2
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    
                    <p>
                        The prompt for this image was "a rocket ship." The 4-step inference didn't yield anything obviously relavent to the promop (maybe I don't know too much about rocket ships), while the 20-step
                        inference yielded a realistic drawing of a rocket ship. The 10-step inference was somewhere in between, having yielded a hybrid between a traditional rocket ship and a bat. 
                        Similar to the previous two prompts, stage 2 upsampled the outputs of stage 1 images to get much clearer images.
                    </p>
                    <p> 
                        I'm using seed = 22 for this problem.
                    </p>
                
                </div>
                <h2 id="part1"> Part A.1.1: Implementing the Forward Process</h2>

                <div class="text-container"> 
                    <p> 
                        To add noises, we follow the following formula:
                        \[
                        q(x_t | x_0) = N(x_t ; \sqrt{\bar\alpha} x_0, (1 - \bar\alpha_t)\mathbf{I})
                        \]
                        After simplification, we arrive at the following equivlaent form:
                        \[
                        x_t = \sqrt{\bar\alpha_t} x_0 + \sqrt{1 - \bar\alpha_t} \epsilon \quad \text{where}~ \epsilon \sim N(0, 1) \tag{0}
                        \]
                        This means that we need to sample from a standard normal distribution and call it \( \epsilon \). For each \(\bar\alpha_t\) from 
                        the alphas_cumprod variable from the scheduler, indexed by t, we iteratively add noises to our clean image. 
                        Here, we display the Campanile with noises added at \(t \in [250, 500, 750]\):
                    </p>  

                    <p> 
                        I'm using seed = 22 for this problem. However, for some sections, I need to use different seeds to ensure the quality and reproducibility of the results.
                    </p>
                    
                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image.jpg", width="200">
                                <figcaption class="caption"> 
                                    Berkeley Campanile
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_250.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=250
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_500.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=500
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_750.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=750
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>
                <!-- End of A.1.1-->
                <h2 id="part2"> Part A.1.2: Classical Denoising</h2>

                <div class="text-container"> 
                    <p> 
                       In this section, I attempted to use classical methods to denoise the test images from the previous part.
                       I used torchvision.transforms.functional.gaussian_blur (kernel = 9, sigma = 2) in order to get the denoised (blurred) versions of the images. 
                       The results are not satisfactory at all, especially the for the image with larger t.
                    </p>  

                    <p> 
                        I'm using seed = 22 for this problem.
                    </p>
                

                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_250.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=250
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_500.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=500
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_nl_750.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=750
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_denoise_250_k_9_s_2.jpg", width="200">
                                <figcaption class="caption"> 
                                    Gaussian Blur Denoising <br/> at t=250
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_denoise_500_k_9_s_2.jpg", width="200">
                                <figcaption class="caption"> 
                                    Gaussian Blur Denoising <br/> at t=500
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_denoise_750_k_9_s_2.jpg", width="200">
                                <figcaption class="caption"> 
                                    Gaussian Blur Denoising <br/> at t=750
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.2-->  
                <h2 id="part3"> Part A.1.3: One-Step Denoising</h2>

                <div class="text-container"> 
                    <p> 
                       In this section, I attempted to denoise the noisy test images using a the pretrained unet. The unet will 
                       estimate both the noise of the current time step. I passed in the noisy image, the time step t, and the prompt embedding into the unet, after which 
                       I used output to reconstruct the denoised image using the following formula.

                       \[
                        x_0 = \frac{x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon}{\sqrt{\bar{\alpha}_t}} \tag{1}
                       \]

                       where \(x_0\) is the clean image, \(x_t\) is the noisy image, \(\epsilon\) is the estimated noise, 
                       and \(\bar{\alpha}_t\) is the alphas_cumprod variable from the scheduler, indexed by t.

                       The following are the results from the denoisign process.
                    </p>  

                    <p> 
                        I'm using seed = 22 for this problem.
                    </p>
                
                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image.jpg", width="200">
                                <figcaption class="caption"> 
                                    Berkeley Campanile
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    
                    <div class="three_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_noisy_250.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=250
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_noisy_500.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=500
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_noisy_750.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=750
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_unet_denoise_250.jpg", width="200">
                                <figcaption class="caption"> 
                                    One-Step Denoised Campanile<br/> at t=250
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_unet_denoise_500.jpg", width="200">
                                <figcaption class="caption"> 
                                    One-Step Denoised Campanile<br/> at t=500
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image_unet_denoise_750.jpg", width="200">
                                <figcaption class="caption"> 
                                    One-Step Denoised Campanile<br/> at t=750
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.3-->  
                <h2 id="part4"> Part A.1.4:  Iterative Denoising</h2>

                <div class="text-container"> 
                    <p> 
                       In this section, I used iterative denoising to achieve more optimal results than one-step denoising. I started with the most noisy time step, \(T = 990\) and iteratively
                       denoised the image with the stride size of -30 until T reached 0. The list of Ts are in the variable called strided timesteps. 

                       In a for loop, I looped through each value of strided timesteps and denoised the image for each time step t. 

                       The algorithm is as follows:
                    </p>  

                    <p> 
                        For each t, I used the following formula to reconstruct the denoised image at that time step.

                        \[
                        x_{t'} = \frac{\sqrt{\bar\alpha_{t'}}\beta_t}{1 - \bar\alpha_t} x_0 +
                        \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t'})}{1 - \bar\alpha_t} x_t +
                        v_\sigma \tag{2}
                        \]

                        Where:
                    </p>
                    <ul>
                        <li><strong>\( t' \):</strong> The previous (index + 1) time step relative to the current time step \( t \).</li>
                        <li><strong>\( \bar{\alpha}_{t'} \):</strong> The cumulative product found in alphas_cumprod at time step \( t' \).</li>
                        <li><strong>\( x_{t'} \):</strong> The denoised image at time step \( t' \).</li>
                        <li><strong>\( \bar{\alpha}_t \):</strong> The cumulative product found in alphas_cumprod at time step \( t \).</li>
                        <li><strong>\( \alpha_t \):</strong> \(\frac{\bar\alpha_t}{\bar\alpha_{t'}}\)</li>
                        <li><strong>\( \beta_t \):</strong> \(1 - \alpha_t\)</li> 
                        <li><strong>\( x_t \):</strong> The noisy image at time step \( t \).</li>
                        <li><strong>\( x_0 \):</strong> The current state of the cleaned image at time step \( t \), retrieved using equation (1). </li>
                        <li><strong>\( v_\sigma \):</strong> The predicted noise variance form the unet.</li>
                    </ul>

                    <p> Specific details about implementation: 
                        <ul>
                            <li> I used <code>add_variance</code> function to add the predicted variance from the unet to the denoised image.</li>
                            <li> I used <code>i_start = 10</code> as the starting time step.</li>
                            <li> I used the estimated noise from the unet as \(\epsilon\) in equation (1) to get \( x_0 \).</li>
                        </ul>
                    </p>

                    <p> 
                        I'm using seed = 22 for this problem. Here are the results.
                    </p>
                
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image.jpg", width="200">
                                <figcaption class="caption"> 
                                    Berkeley Campanile Original
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_clean_final.jpg", width="200">
                                <figcaption class="caption"> 
                                    Iteratively Denoised Campanile
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_clean_one_step.jpg", width="200">
                                <figcaption class="caption"> 
                                    One-Step Denoised Campanile
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_gaus.png", width="200">
                                <figcaption class="caption"> 
                                    Gaussian Blurred Campanile
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_unet_denoise_90.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=90
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_unet_denoise_240.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=240
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_unet_denoise_390.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=390
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_unet_denoise_540.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=540
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/iter/test_image_iter_unet_denoise_690.jpg", width="200">
                                <figcaption class="caption"> 
                                    Noisy Campanile at t=690
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.4-->  
                <h2 id="part5"> Part A.1.5: Diffusion Model Sampling</h2>

                <div class="text-container"> 
                    <p> 
                       In this section, used the trained unet diffusion model to denoise pure noise with the embedded guidance of "a high quality photo". To denoise images from random
                       noises, I set <code>i_start = 0</code> and passed in a random noise, sampled from a standard normal distribution, with the shape of (5, 3, 64, 64), five images sampled at once. The model sampling/ reconstruction loop is the same as A.1.4.
                    </p>

                    <p> 
                        Though the following sampled images are not very good, they are decent in quality.
                    </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/img_0.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/img_1.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/img_2.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 3
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/img_3.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 4
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/img_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 5
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.5-->  
                <h2 id="part6"> Part A.1.6: Classifier-Free Guidance (CFG)</h2>

                <div class="text-container"> 
                    <p> 
                       In this section, I used classifier-free guidance to improve the quality of the denoised images. The CFG algorithm involves running the unet model twice, once as an unconditional unet and once as a conditional unet.
                       I used the null prompt, '', as the embedded prompt for the unconditional unet and the original prompt, 'a high quality photo', as the embedded prompt for the conditional unet. The output of the unconditional unet is called
                       \(\epsilon_u\) and the output of the conditional unet is called \(\epsilon_c\). Using the equation below, I got the final noise at the current time step.

                    <p> 
                     \[
                     \epsilon = \epsilon_u + \gamma
                     (\epsilon_c - \epsilon_u) \tag{3}
                     \]
                    </p>

                    <p> 
                        \(\gamma\) is the guidance scale, a variable that controlls how much guidance the final noise receives. When \(\gamma = 1\), the estimated noise is purely conditional, while when \(\gamma = 0\), the estimated noise is purely unconditional.
                        To make the magic happen, I set \(\gamma = 7\) per the spec's recommendation.
                    </p>

                    <p> 
                        After getting the guided estimated noise, the rest of the image denoising process is the same as A.1.5. Here are 5 samples from the iterative denoising process with CFG. I would say they are of much higher quality (clearer and more vibrant) than the samples from the previous section.
                    </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/cfg_img_0.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/cfg_img_1.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 2
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/cfg_img_2.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 3
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/cfg_img_3.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 4
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/cfg_img_4.jpg", width="200">
                                <figcaption class="caption"> 
                                    Sample 5
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.6-->  
                <h2 id="part7"> Part A.1.7: Image-to-image Translation </h2>

                <div class="text-container"> 
                    <p> 
                        In this section I used the SDEdit algorithm to iteratively guide, CFG, the noisy image back to its something resembling the original image. To do so, I followed the following steps:
                    <p> 
                    
                    <ul>
                        <li> I added noise to the chosen image by running the forward method outlined in equation (0). </li>
                        <li> I then used "a high quality photo" as the embedded prompt to guide the denoising process at time steps [1, 3, 5, 7, 10, 20]. </li>
                        <li> I applied these two steps on the test image and two other images of my choice. </li>
                        <li> The <B>seed</B> is 100 for all three images.</li>
                    </ul>

                    <p> Test Image SDEdit: </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_test_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image.jpg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Berkeley Campanile
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> Burney Fall SDEdit: </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_fall_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/data/small/fall.jpeg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Burney Fall
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> Yosemite SDEdit: </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/sampling/sde_cfg_yosemite_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    SDEdit with <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/data/small/yosemite.jpeg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Yosemite
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.7-->  
                <h2> Part A.1.7.1: Editing Hand-Drawn and Web Images </h2>

                <div class="text-container"> 
                    <p> 
                       Now it's time to apply the SDEdit technique to web images and hand-drawn images. To do so, I downloaded one web image and drew 2 images by hand, after which I applied the same procedure as the previous part and recorded the results and 
                       intermediate images.
                    <p> 

                    <p> Kangaroo (Web) SDEdit: 
                        <br/>
                        <a href="https://c02.purpledshub.com/uploads/sites/62/2024/07/kangaroo-facts.jpg?w=1029&webp=1">Kangaroo Image Link</a>
                    </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_9.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 9</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/kangaroo_start_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    Kangaroo at <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/data/small/kangaroo.jpg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Kangaroo
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> Hand-drawn Leaf SDEdit: </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_9.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 9</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/leaf_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    Leaf at <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/drawn_leaf.jpg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Hand-drawn Leaf
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> Hand-drawn Tree SDEdit: </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_1.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 1</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_3.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 3</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_5.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 5</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_7.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 7</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_9.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 9</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_10.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 10</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/tree_20.jpg", width="130">
                                <figcaption class="caption"> 
                                    Tree at <br/> 
                                    <code>i_start = 20</code>
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hand-web/drawn_tree.jpg", width="130">
                                <figcaption class="caption"> 
                                    Original Image <br/>
                                    Hand-drawn Tree
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.7.1-->  

                <h2 id="part7.2"> Part 1.7.2 Inpainting </h2>

                <div class="text-container">
                    <p> 
                        To allow inpainting, we use a binary mask to allow new image to be painted when the mask is 1 and keeps the original image's noises when the mask is 0. 
                        To achieve this effect we need to use the following equation after we get the denoised image \( x_t \) at each time step \( t \).
                    <p> 
                        \[
                        x_t \leftarrow \textbf{m} x_t + (1 - \textbf{m})
                        \text{forward}(x_{orig}, t) \tag{4}
                        \]
                        Where: 
                        <ul>
                            <li>\( x_t \): The denoised image at time step \( t \).</li>
                            <li>\( x_{orig} \): The original image.</li>
                            <li>\( \textbf{m} \): The binary mask.</li>
                        </ul>
                    </p>

                    <p> Here are the results from the inpainting process. </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/test_og.jpg", width="200">
                                <figcaption class="caption"> 
                                    Campanile
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/test_mask.jpg", width="200">
                                <figcaption class="caption"> 
                                    Mask
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/test_replace.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hole to Fill
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/test_clean.jpg", width="200">
                                <figcaption class="caption"> 
                                    Campanile Inpainted (Seed = 2)
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/hat_og.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hat
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/hat_mask.jpg", width="200">
                                <figcaption class="caption"> 
                                    Mask
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/hat_replace.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hole to Fill
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/hat_clean.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hat Inpainted (Seed = 9912)
                                </figcaption>
                            </figure>
                        </div>
                    </div>
            
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/chick_og.jpg", width="200">
                                <figcaption class="caption"> 
                                    Proud Snackpass Chick
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/chick_mask.jpg", width="200">
                                <figcaption class="caption"> 
                                    Mask
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/chick_replace.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hole to Fill
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/inpaint/chick_clean.jpg", width="200">
                                <figcaption class="caption"> 
                                    Chick Inpainted (Seed = 900)
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>
                <!-- End of A.1.7.2-->  
                <h2 id="part7.3"> Part 1.7.3 Text-Conditioned Image-to-image Translation </h2>

                <div class="text-container">
                    <p> 
                        The text-conditioned image-to-image translation requires us to change the conditioning prompt from "a high quality photo" to any of the given prompts. 
                        For this section, I used "a rocket ship" for the test image, "a lithograph of a river" for the Yosemite image, and "a rocket ship" for the street light image.
                    </p> 

                    <p> Here are the results using text-conditioning with <B>seed</B> = 100. </p>
                    
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_1.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_3.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 3
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_5.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 5
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_7.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 7
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_10.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 10
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/rocket_noise_20.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket Ship at noise 
                                    <br/> 
                                    level 20
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/test_image.jpg", width="150">
                                <figcaption class="caption"> 
                                    Original Image 
                                    <br/>
                                    Campanile
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_1.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_3.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 3
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_5.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 5
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_7.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 7
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_10.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 10
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/fall_clean_20.jpg", width="150">
                                <figcaption class="caption"> 
                                    River at noise 
                                    <br/> 
                                    level 20
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/data/small/yosemite.jpeg", width="150">
                                <figcaption class="caption"> 
                                    Original Image 
                                    <br/>
                                    Yosemite
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_1.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_3.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 3
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_5.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 5
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_7.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 7
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_10.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 10
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/text-cond/light_clean_20.jpg", width="150">
                                <figcaption class="caption"> 
                                    Rocket (Light) at noise 
                                    <br/> 
                                    level 20
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/data/small/light.jpeg", width="150">
                                <figcaption class="caption"> 
                                    Original Image 
                                    <br/>
                                    Street Light
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>
                <!-- End of A.1.7.3--> 
                <h2 id="part8"> Part A.1.8: Visual Anagrams</h2>

                <div class="text-container"> 
                    <p> 
                        Now it's time for something fun! In this section, I used the pretrained denoiser model to create various anagrams using two text prompts as guidances. The result should look like
                        the first guidance prompt when rightside up and the second guidance prompt when upside down. To do so, I followed the following equations to process the estimated noise:
                    </p>

                    <p>
                        \[
                        \epsilon_1 = \text{UNet}(x_t, t, p_1) \tag{5}
                        \]
                        \[
                        \epsilon_2 = \text{flip}(\text{UNet}(\text{flip}(x_t), t, p_2)) \tag{6}
                        \]
                        \[
                        \epsilon = (\epsilon_1 + \epsilon_2) / 2 \tag{7}
                        \]
                    </p>

                    <p> 
                        For the first text prompt \(p_1\), I used equation (5) to estimate the noises \(\epsilon_1\) of the image at each time step. Then, I used equation (7) to retrieve the estimated noise in 
                        the flipped image (along the height axis) using \(p_2\) as the conditional prompt. Finally, I used equation (7) to estimate the total noise by averaging the two estimated noises \(\epsilon_1\) and \(\epsilon_2\).
                        Note that we also need CFG here, so I created the unconditional noises for both original and flipped images separately using the null prompt. Then, I applied the CFG algorithm separately to \(\epsilon_1\) and \(\epsilon_2\) 
                        before I averaged them. The two prompts shared the same guidance scale. Everything else is the same as text-conditioned iterative denoising.
                    </p>

                    <p>
                        Here are some of the results:
                    </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/man_fire.jpg", width="300">
                                <figcaption class="caption"> 
                                    An Oil Painting of an Old Man
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/man_fire.jpg", width="300", style="transform: scaleY(-1);">
                                <figcaption class="caption"> 
                                    An Oil Painting of People around a Campfire
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/man_village.jpg", width="300">
                                <figcaption class="caption">    
                                    An Oil Painting of an Old Man
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/man_village.jpg", width="300", style="transform: scaleY(-1);">
                                <figcaption class="caption"> 
                                    An Oil Painting of a Snowy Mountain Village
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/village_fire.jpg", width="300">
                                <figcaption class="caption"> 
                                    An Oil Painting of a Snowy Mountain Village
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/anagram/village_fire.jpg", width="300", style="transform: scaleY(-1);">
                                <figcaption class="caption"> 
                                    An Oil Painting of People around a Campfire
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    
                </div>  
                <!-- End of A.1.8--> 
                
                <h2 id="part9"> Part A.1.9: Hybrid Images</h2>

                <div class="text-container"> 
                    <p> 
                        We can also try to make some hybrid images that look like the first prompt when far away and the second prompt when close up. In principle, we can just take the low frequncyies of
                        the image conditioned by the first prompt, take the high frequencies of the image conditioned by the second prompt, and average them together to get the final noise. The resulting image 
                        should retain the low frequencies from the first prompt and the high frequencies from the second prompt, thus creating a hybrid effect. Here are the equations and how to use them.
                    </p>

                    <p>
                        \[
                        \epsilon_1 = \text{UNet}(x_t, t, p_1) \tag{8}
                        \]
                        \[
                        \epsilon_2 = \text{UNet}(x_t, t, p_2) \tag{9}
                        \]
                        \[
                        \epsilon = f_\text{lowpass}(\epsilon_1) + f_\text{highpass}(\epsilon_2) \tag{10}
                        \]
                    </p>

                    <p> 
                        Similar to A.1.8, I useded equation (8) to estimate the noises \(\epsilon_1\) of the image at each time step using the first prompt \(p_1\). Then, I used equation (9) to retrieve the estimated noise for 
                        the second prompt \(p_2\). The only difference was that I didn't need to flip the image for the second prompt. Finally, I used two Gaussian blurs with kernel = 33 and sigma = 2 to retrieve the low frequency noises
                        of \(\epsilon_1\) and \(\epsilon_2\). The high frequency noises of prompt two was the difference between the original image and the low frequency noises of prompt two. Using equation (10), I added the low frequency
                        from prompt one to the high frequency from prompt two to get the final noise. I also used CFG for prompt one and prompt two separately and applied the guidance scale before adding the noises to get the final noise.
                    </p>

                    <div class="linear"> 
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hybrid/skull_fall.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hybrid image of <br/> 
                                    a skull and a waterfall
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hybrid/skull_camp.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hybrid image of 
                                    <br/> 
                                    a skull and a campfire
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_A/part 1/hybrid/skull_forest.jpg", width="200">
                                <figcaption class="caption"> 
                                    Hybrid image of 
                                    <br/> 
                                    a skull and a forest
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of A.1.9--> 
                <h2 id="partB.1.1"> Part B.1.1: Implementing the UNet</h2>

                <div class="text-container"> 
                    <p> 
                        In this section, I implemented the unconditional UNet using various convolutional blocks and concatination layers. The high level idea of this UNet is that it 
                        downsamples the image from the original size into a 1 by 1 by 2D tensor, learning the image along the way. Then, it upsamples the image from the 1 by 1 by 2D tesnor back into the 
                        original size, combining the results from downsampling along the way through concatination. This structure can be used to transform the input image.
                    </p>

                    <p>
                        Here is the general architecture of the UNet (borrowed from the project spec):
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/unconditional_arch.png", width="500">
                                <figcaption class="caption"> 
                                    Uncondtional UNet
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        To implement the UNet, I added both the block initilization and the forward method of each block. Then, I combined everything into the UNet class, adding necessary layers and filling in the 
                        foward methods. After constructing the UNet architecture, I'm ready to start training a denoiser for the MNIST dataset.
                    </p>

                    <p> 
                        I used 22 as the <code>SEED</code>.
                    </p>
                </div>  
                <!-- End of A.2.1--> 
                <h2 id="partB.1.2"> Part B.1.2: Using the UNet to Train a Denoiser</h2>

                <div class="text-container"> 
                    <p> 
                        To train the network, I needed to identify a loss funciton first. Per the spec's suggestion, I used an average L2 loss between the estimated clean image and the true clean image.
                        Here is the loss function:
                    </p>

                    <p>
                        \[
                            L = \mathbb{E}_{z,x}\| D_{\theta}(z) - x\|^2. \tag{11}
                        \]
                        Where: 
                        <ul> 
                            <li>\(D_{\theta}(z)\) is the estimated clean image from the model.</li>
                            <li>\(x\) is the original image.</li>
                        </ul>
                    </p>

                    <p> 
                        To prepare the data for training, I artificially added noises to the MNIST train dataset using the following equation: 
                    </p>

                    <p>
                       \[
                       z = x + \sigma \epsilon,\quad \text{where }\epsilon \sim N(0, I). \tag{12}
                       \]
                    </p>

                    <p> 
                        For demonstration, I used \(\sigma = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\) to add noises to the numbers 7, 2, 1, 0, and 4. Here is the result.
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/noisy_numbers.jpg", width="1000">
                                <figcaption class="caption"> 
                                    Varying levels of noise on MNIST digits
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of B.2--> 
                <h2 id="partB.1.2.1"> Part B.1.2.1: Training </h2>

                <div class="text-container"> 
                    <p> 
                        I constructed a training loop that trains the UNet for 5 epochs on the shuffle MNIST train dataset. I started to train the denoiser using the following parameters:
                    </p>
                    
                    <ul>
                        <li> \(\text{D} = 128\)</li> 
                        <li> \(\text{Number of epochs} = 5\)</li>
                        <li> \(\text{Batch size} = 256\)</li>
                        <li> \(\text{learning rate} = 0.0001\)</li>
                        <li> \(\text{Optimizer} = Adam \)</li>
                    </ul>

                    <p> 
                        Note that I only added noise to the train images right before it was fed into the model so that the model can see a 
                        different noise each time. The noise at each time step was added using equation (12). Within the training loop, I also collected the training loss and graphed the output at 
                        appropriate intervals. Here are the results:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/uncond_train_losses.jpg", width="800">
                                <figcaption class="caption"> 
                                    Uncondtional Model Training Loss Curve
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/uncond_results_1.jpg", width="800">
                                <figcaption class="caption"> 
                                    Results on digits from the test set after 1 epoch of training.
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/uncond_results_5.jpg", width="800">
                                <figcaption class="caption"> 
                                    Results on digits from the test set after 5 epoch of training.
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        The training loss showed a drastic decrease in epoch 1 and gradually levels off at a very small number.
                        The results on the digits from the test set after 1 epoch was not as accurate and defined as the ones after
                        5 epochs of training, which was expected.
                    </p>
                </div>  
                <!-- End of B.1.2.1--> 
                <h2 id="partB.1.2.1"> Part B.1.2.2: Out-of-Distribution Testing </h2>

                <div class="text-container"> 
                    <p> 
                        After the model had been trained for 5 epochs, I applied the model to the same number 7 image with different levels of noises.
                        For each \(\sigma\) in the list \(\sigma = [0.0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0]\), I added noises to the number 7 and then 
                        used the model to predict the denoised image. Here are the results:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/out_of_dist_test.jpg", width="800">
                                <figcaption class="caption"> 
                                    Uncondtional Model Training Loss Curve
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        The denoised results were very good for \(\sigma <= 0.5\). For \(\sigma > 0.5\), the model tended to add some artifacts to the image probably because the
                        model was not trained to handle more these higher noise levels. Our current model still needed improvment.
                    </p>
                </div>  
                <!-- End of B.1.2.2--> 
                <h2 id="partB.2"> Part B.2: Training a Diffusion Model</h2>

                <div class="text-container"> 
                    <p> 
                        With the unconditional UNet under our belts, we could train a similar network to estimate the noise at each level, thus building ourselves a diffusion model.
                        The new objective begged for a new objective funciton. Instead of minimizing the loss between the estimated final image and the original image, we minimized 
                        the L2 (MSE) difference between the predicted noise and the true noise. 
                        
                        \[
                        L = \mathbb{E}_{\epsilon,z} \|\epsilon_{\theta}(z) - \epsilon\|^2 \tag{13}
                        \]

                        where \(\epsilon_{\theta}(z)\) is the predicted noise from the UNet.
                    </p>

                    <p>
                        To add noise, we used equation (0) from part A at each time step in the training process.
                    </p>
                </div>  
                <!-- End of B.2-->
                <h2 id="partB.2.1"> Part B.2.1 - B.2.3: Adding Time Conditiong to UNet</h2>

                <div class="text-container"> 
                    <p> 
                        To add time conditioning so that we can train the model to predict noise at each time step, we first needed to change the model structure.
                        We added an additional parameter, called t, to the model function signature. Under the hood, we used an FCBlock to embed the scalar t to fit 
                        the dimension of the convolutional layers. Then we added the embedded t to the unflattened and the first upsampled blocks of the architecture. Here is a diagram:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/time_conditional_arch.png", width="800">
                                <figcaption class="caption"> 
                                    Time Conditioned Model Architecture
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        The FCBlock consists of two fully connected layers and one layer of GELU activation. It can embed the scaler t and make it understandable to our model.
                    </p>

                    <p> 
                        To construct the training loop, I first set up a training schedule that contained precomputed \(\beta_t\), \(\alpha_t = 1 - \beta_t\), and \(\bar\alpha_t = \prod_{s=1}^t \alpha_s\). I first calculated \(\beta_t\), which was
                        a list of numbers that were evenly space from 0.0001 to 0.02 with the total length being 300. Then I found the rest of the variables using this piece of information.
                    </p>

                    <p>
                        The training loop is as follows:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/algo1_t_only.png", width="800">
                                <figcaption class="caption"> 
                                    Time Conditioned Training Loop
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        I got the precomputed \(\bar\alpha\) from the scheduler. For each time step t, I sampled the noise from a standard normal distribution and added the noise to the image 
                        according to equation (0). Then, I passed the noise and the normalized t into the model to get the predicted noise, after which I minimized the loss. I repeated this process for the number of epochs.
                    </p>

                    <p>
                        The training parameters stayed similar except that I used an exponential learning rate scheduler to slow down the gradient descent after each epoch. The number of epochs was increased to 20, and the hidden dimension was decreased to 64.
                    </p>

                    <p>
                        Here is the training loss curve through out the 20 epochs:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_cond_loss.png", width="800">
                                <figcaption class="caption"> 
                                    Time-Conditioned UNet training loss curve
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        Now that I had the trained UNet, I could start to sample from it. To sample, I followed the alogrithm below to reconstruct the clean image at each time step using the noise output form
                        the model. Here is the algorithm:
                    </p> 

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/algo2_t_only.png", width="800">
                                <figcaption class="caption"> 
                                    Time-Conditioned UNet sampling algorithm
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        I retrieved the elements from the scheduler and followed the steps outlined in the diagram to iteratively denoise the image. On the high level, the algorithm iteratively inversed the noise adding process.
                        For each t (from large to small), I estimated the clean image at that time step using the output of the model. Then, I used more information from the scheduler to reconstruct the cleaned image for the next step. 
                        I repeated for all t from T to 1 and outputed the final image. Here are some results:
                    </p>

                    <div class="image_container"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_results_01.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_results_05.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 5
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_results_10.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 10
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_results_15.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 15
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/time_results_20.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 20
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of B.2.1-->
                <h2 id="partB.2.4"> Part B.2.4 - B.2.5: Adding Class Conditiong to UNet</h2>

                <div class="text-container"> 
                    <p> 
                        I added two more FCBlocks for the class conditional UNet. Each block takes in the one-hot encoded class condtioner and embeds it to fit the dimension of the convolutional 
                        layers. The first embedded class vector was added to the unflattened tensor via direct product (before adding time conditioning). The second class embedding was added to the upsample 1 
                        tensor through direct product as well before adding time conditioning. I also added a dropout mask (a tensor of zeros) to ensure tha we only consider class conditioning 90% of the time.
                    </p>

                    <p> 
                       The training loop for this section is very similar to the one for teim conditioning. The only difference was that we needed to use the labels as one-hot encoded condition vector. We also needed
                       to apply dropout 10% of the time as well. I used a Bernoulli random variable as the indictor with 90% of success rate and 10% of failure rate. If the random variable fails (returns 0), I would 
                       multiply the one-hot encoded class with the mask to set it to zero.
                    </p>

                    <p>
                        The training loop is as follows:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/algo3_c.png", width="800">
                                <figcaption class="caption"> 
                                    Class Conditioned Training Loop
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        I got the precomputed \(\bar\alpha\) from the scheduler. For each time step t, I sampled the noise from a standard normal distribution andadded the noise to the image 
                        according to equation (0). Then, I passed the noise, the normalized t, and the class conditioning vectors into the model to get the predicted noise, after which I minimized the loss. I repeated this process for the number of epochs.
                    </p>

                    <p>
                        The training parameters stayed similar except that I used a exponential learning rate scheduler to slow down after each epoch. The number of epochs was increased to 20, and the hidden dimension was decreased to 64.
                    </p>

                    <p>
                        Here is the training loss curve through out the 20 epochs:
                    </p>

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_losses.jpg", width="800">
                                <figcaption class="caption"> 
                                    Class-Conditioned UNet training loss curve
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        Now that I had the trained UNet, I could start to sample from it. To sample, I followed the alogrithm below to reconstruct the clean image at each time step using the noise output form
                        the model. Here is the algorithm:
                    </p> 

                    <div class="single_col"> 
                        <div class=image>
                            <figure> 
                                <img src="data/algo4_c.png", width="800">
                                <figcaption class="caption"> 
                                    Class-Conditioned UNet sampling algorithm
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p> 
                        The general approach was similar to the one for time-conditioned UNet. The only difference was that I added an unconditional guidance and added it with the guided
                        noise under the guidance scale. More concretely, I called the UNet model twice, once on the unconditional prompt (tensor of all zeros) and once one the one-hot encoded 
                        classes that I wanted to generate. The process is the same as the CFG in part A. I chose the guidance scale to be 5. Here are some results:
                    </p>

                    <div class="image_container"> 
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_results_1.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 1
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_results_5.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 5
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_results_10.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 10
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_results_15.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 15
                                </figcaption>
                            </figure>
                        </div>
                        <div class=image>
                            <figure> 
                                <img src="data_B/class_results_20.jpg", width="400">
                                <figcaption class="caption"> 
                                    Epoch 20
                                </figcaption>
                            </figure>
                        </div>
                    </div>
                </div>  
                <!-- End of B.2.5-->
                <h2 id="conclusion"> Conclusion </h2>

                <div class="text-container"> 
                    <p> 
                        This is by far the most interesting and rewarding project I have ever done. I got a chance to learn so much about image-to-image translation from theory to implementation, from seed to fruition. 
                        As fun as this project is, it wasn't without many challenges. I had to familiarize myself with Google Colab very quickly and learn to use GPU resources efficiently. There were several bugs that
                        seemed impossible to solve, but I managed to locate the mistakes and eradicate them on time. I would love to do more projects like this in the future.
                    </p>
                </div>  
                <!-- End of Conclusion-->
            </div>
        </div>
    </body>
</html>
